---
layout: post
title:  "An Album paints a Thousand Words: NLP And Autoencoders for Music Recommendation"
author: Lev
categories: [ Machine Learning ]
tags: [ Deep Learning, Music, NLP ]
comments: true
image: assets/images/albums/autoencoder_main.jpg
---

They say a picture paints a thousand words.
The same could be said for a piece of music, or any work of art for that matter.
While I don't frequent art forums, I have in the past visited music review sites and have read many of the reviews
posted there, be they reviews of singles, albums, or concerts.
Often, a thousand words or more (usually less, as we'll see) are used directly to describe a piece of music by a
journalist trying to critically analyse it. Perhaps an analysis of these words directly can give us an insight as to how we can
categorize the album involved.

A few months ago, I stumbled upon [this](https://www.kaggle.com/nolanbconaway/pitchfork-data) dataset on 
Kaggle which contains a whopping 18,393 album reviews from the music website Pitchfork, containing all reviews
posted from Jan 5, 1999 to Jan 8, 2017.
I found this dataset at a time when I was performing research on Autoencoders for a project in work
and I was keen to apply this cool Machine Learning architecture
to an interesting real-world dataset. Using some common NLP (Natural Language Processing) techniques and a simple
Autoencoder Neural Network I was able to achieve just that. The idea I had was: 

### Would it be possible to create album recommendations calculating the distance between albums in some latent space, using an autoencoder?

You may be asking;

## What is an Autoencoder?

An **Autoencoder** is a type of Neural Network that consists of an encoder and a decoder and is primarily used 
to perform dimensionality reduction on high-dimensional data. It has other uses, such as image compression, 
feature extraction, and more. The [following](https://iq.opengenus.org/applications-of-autoencoders/) is a nice
article running through the other uses, giving some nice visual examples.

![](https://datakeen.co/wp-content/uploads/2018/02/S%C3%A9lection_106.png)
*A rough sketch of an autoencoder. Source: datakeen.co*

The main idea is that you feed data into the neural network, and train the model by comparing the
reconstructed data outputs to the original inputs. Using the above image an example, you reduce dimensionality of a sample
from layer *X* to layer *Z*, e.g 784-dimensional data to 2 dimensional data, using an encoder. You then decode the
2-dimensional data to the 784-dim data using the decoder and compare the output to the original input.
The difference between input and output is what the network is trained on.

The thinking is that if your output *X'* matches perfectly with original input *X*, then the 2-dimensional data 
generated by the encoder part of the network is a good representation of of the 784-dimensional data.

The lower dimensional data can then be used for other tasks such as clustering.

## Analysing text using TF-IDF

To apply this modelling approach to the album review dataset, you would first have to turn the albums
into some dataset that can be fed into a neural network. To do this, I decided to use a statistical 
technique called **TF-IDF**, or **T**erm **F**requency-**I**nverse **D**ocument **F**requency. This is used to measure the
relevance of a word in a document, also taking into account how often it occurs in an entire set of documents.
This relevance is assigned a numeric score, and a selection of key words can be selected to describe
a set of documents.

A brief explanation if this technique can be found [here](https://monkeylearn.com/blog/what-is-tf-idf/).

Here is a toy example. If we take all the albums in the dataset and apply TF-IDF to find the 10 most
relevant words to the dataset and how important they are for each document, we get a dataframe that looks like this:

![](/assets/images/albums/album_df.png)

In the example above, TF_IDF returned that the word *rock* may be used to describe some albums, where they have a positive number in that column.
If the album has a 0 for the *rock* column, it indicates it was not used, or not used enough to be considered relevant.
The larger the value; the stronger the relevance.
For Mezzanine, words *album* and *band* appear more important than *rock* or *sound*, due to the frequency of occurrence within the review.
This gives is a 10 dimensional vector to represent each document.
These vectors don't contain a lot of information, and in practice we would like some informative data to feed to the model.

I looked at the distribution of album length to decide how many of the words I want TF-IDF to identify from each document in the dataset.

![](/assets/images/albums/albumhist.jpg)

There is an average of 650 words in each review, however there will always be words used in some reviews not used in others,
and I figured going for a round 1000 words would cover a lot of the text data.
I later experimented with this number, but adding more than 1000 words didn't seem
to add much information, although a proper investigation into this would be interesting.

## Applying an autoencoder to vectorized dataset

With those two explanations out of the way, we can look at the results of the modelling.
For the autoencoder implementation I used PyTorch, and for the TF-IDF I used the scikit-learn TfidfVectorizer.
All of the code I used can be found on my [Github page](https://github.com/LevUdaltsov/album_recommender/tree/main).
The autoencoder consists of an encoder with an input layer of 1000, hidden layers 256, 64, 12, 2, and a decoder with hidden
layers 2, 12, 64, 256, and an output layer of 1000. I experimented with different amounts of layers and different layers, 
and found this combination to work well. It was trained for 200 epochs with a batch size of 100.

The hyperparameter choice requires a lot more testing and tuning but for an initial experiment this was sufficient.

So, what can we learn from encoding the album reviews? Here is a couple examples of artists and their albums plotted in the 
2-dimensional space to which the data was encoded.

![](/assets/images/albums/album_plot_1.png)
*Plot of 2 dimensional representations of albums for four selected artists*

In the above plot we see that the model was able to learn some sort of information about the albums. For each artist,
the albums seem to cluster within a certain space, with a few outliers for the Kanye and Kendrick albums.
Coldplay's albums are closest together. This is a really interesting to see.

Here is another example, this time without labels to get a clearer image.
![](/assets/images/albums/album_plot_no_label.png)

Again, we see that aside from a few stragglers, albums are being plotted near each other.
In both plots, the Hip-Hop albums are plotted closer to other Hip-Hop albums, than the Rock or Pop or Electronic Music
records are.

Using Autoencoders and NLP it was possible to boil down lengthy text reviews to data in 2 dimensional space!

## Using results for recommendation

Next, I tried using these points in space as a way of recommending new music. 
Using the geometric mean of a number of albums, I would located the closest album that had a pitchfork rating greater than 8.0,
and passed it as a recommendation.
![](/assets/images/albums/recommendation_2.png)

Here is a visualisation of these four albums, and the recommendation it returns located in between them.
![](/assets/images/albums/recommendation.png).

What the system returned was a an album of various old soul/funk songs from a small Detroit label;
[*Eccentric  Soul: The Big Mack Label*](https://open.spotify.com/album/2dGg3NFqftr5ufcgzakbW0?si=D3TEZ70JTSKwPyNXV3kuCw)

It's a great listen and I'm listening to it now as I edit this article! The model generated a few other recommendations
that I have really enjoyed and would never have come across myself. I will post another article outlining these soon.

Overall, while I haven't figured out how to apply standard recommendation system testing or validation to this, 
I think that it has been a very interesting experiment. Some next steps I have in mind are:

* Comprehensibilty Analysis
* Hyper Parameter fine-tuning
* Application to other datasets

Keep an eye out for these in future posts on my blog! 
